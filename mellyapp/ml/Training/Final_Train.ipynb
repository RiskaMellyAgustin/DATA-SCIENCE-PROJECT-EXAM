{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32890a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 15.21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv(\"D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/mellyapp_dataset_OLAP.csv\")\n",
    "X = df.drop('grade', axis=1)\n",
    "y = df['grade']\n",
    "\n",
    "# 2. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "])\n",
    "\n",
    "# 4. Grid Search (opsional → bisa langsung pakai default jika mau simple)\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100],\n",
    "    'model__max_depth': [3],\n",
    "    'model__learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluasi\n",
    "y_pred = grid.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f\"XGBoost RMSE: {rmse:.2f}\")\n",
    "\n",
    "# import os\n",
    "\n",
    "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# model_path = os.path.join(BASE_DIR, 'xgboost_model.pkl')\n",
    "\n",
    "# joblib.dump(grid.best_estimator_, model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d8619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 15.21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv(\"D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/mellyapp_dataset_OLAP.csv\")\n",
    "X = df.drop('grade', axis=1)\n",
    "y = df['grade']\n",
    "\n",
    "# 2. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "])\n",
    "\n",
    "# 4. Grid Search (opsional → bisa langsung pakai default jika mau simple)\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100],\n",
    "    'model__max_depth': [3],\n",
    "    'model__learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluasi\n",
    "y_pred = grid.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f\"XGBoost RMSE: {rmse:.2f}\")\n",
    "\n",
    "# import os\n",
    "\n",
    "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# model_path = os.path.join(BASE_DIR, 'xgboost_model.pkl')\n",
    "\n",
    "# joblib.dump(grid.best_estimator_, model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d900ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Summary ===\n",
      "           stu_id   course_id      gender         age  total_activities  \\\n",
      "count  479.000000  479.000000  479.000000  479.000000        479.000000   \n",
      "mean    50.678497    3.004175    0.396660   21.640919          2.791232   \n",
      "std     28.764245    1.418638    0.489716    2.160039          0.551004   \n",
      "min      1.000000    1.000000    0.000000   18.000000          1.000000   \n",
      "25%     26.000000    2.000000    0.000000   20.000000          3.000000   \n",
      "50%     51.000000    3.000000    0.000000   22.000000          3.000000   \n",
      "75%     75.000000    4.000000    1.000000   23.000000          3.000000   \n",
      "max    100.000000    5.000000    1.000000   25.000000          3.000000   \n",
      "\n",
      "       total_duration_minutes  quiz_count  individual_assignment_count  \\\n",
      "count              479.000000  479.000000                   479.000000   \n",
      "mean                90.394572    0.352818                     1.768267   \n",
      "std                 34.920364    0.775371                     1.377705   \n",
      "min                  5.000000    0.000000                     0.000000   \n",
      "25%                 66.000000    0.000000                     1.000000   \n",
      "50%                 90.000000    0.000000                     2.000000   \n",
      "75%                114.500000    0.000000                     3.000000   \n",
      "max                211.000000    3.000000                     6.000000   \n",
      "\n",
      "       group_assignment_count  forum_count       grade  \n",
      "count              479.000000   479.000000  479.000000  \n",
      "mean                 2.185804     1.085595   75.304802  \n",
      "std                  1.071174     1.052483   14.719945  \n",
      "min                  1.000000     0.000000   50.000000  \n",
      "25%                  1.000000     0.000000   62.000000  \n",
      "50%                  2.000000     1.000000   75.000000  \n",
      "75%                  3.000000     2.000000   88.000000  \n",
      "max                  6.000000     3.000000  100.000000  \n",
      "\n",
      "=== Correlation with Grade ===\n",
      "grade                          1.000000\n",
      "individual_assignment_count    0.045373\n",
      "course_id                      0.044420\n",
      "group_assignment_count         0.004892\n",
      "quiz_count                    -0.021723\n",
      "total_duration_minutes        -0.032692\n",
      "total_activities              -0.036245\n",
      "stu_id                        -0.036326\n",
      "gender                        -0.039154\n",
      "forum_count                   -0.043954\n",
      "age                           -0.046161\n",
      "Name: grade, dtype: float64\n",
      "R^2 Score: -0.36\n",
      "RMSE: 17.45\n"
     ]
    }
   ],
   "source": [
    "# train_xgboost_model.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/OLAP_FINAL.csv\")\n",
    "\n",
    "# Step 1: Data Cleaning\n",
    "df.dropna(inplace=True)  # Drop missing values if any\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Step 2: EDA (Quick)\n",
    "print(\"=== Data Summary ===\")\n",
    "print(df.describe())\n",
    "print(\"\\n=== Correlation with Grade ===\")\n",
    "print(df.corr(numeric_only=True)[\"grade\"].sort_values(ascending=False))\n",
    "\n",
    "# Step 3: Feature and Target Separation\n",
    "X = df.drop(columns=[\"grade\", \"stu_id\",\"course_id\"])  # Exclude grade and student ID\n",
    "y = df[\"grade\"]\n",
    "\n",
    "# Step 4: Preprocessing\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        \n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Model Pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 6: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Train Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred):.2f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}\")\n",
    "\n",
    "# # Step 9: Save Model\n",
    "# joblib.dump(model, \"xgboost_model.pkl\")\n",
    "# print(\"Model saved as xgboost_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22596f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
