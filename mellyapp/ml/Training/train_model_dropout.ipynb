{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e4b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76        79\n",
      "           1       0.14      0.14      0.14        21\n",
      "\n",
      "    accuracy                           0.63       100\n",
      "   macro avg       0.45      0.45      0.45       100\n",
      "weighted avg       0.64      0.63      0.63       100\n",
      "\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[60 19]\n",
      " [18  3]]\n",
      "\n",
      "=== ROC AUC Score ===\n",
      "0.41169379144062684\n",
      "\n",
      "=== 5-Fold Cross-Validated F1 Score: 0.1537 ===\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv('D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/melly_dataset_dropoutcsv.csv')\n",
    "\n",
    "# 2. Encode categorical data (gender)\n",
    "le = LabelEncoder()\n",
    "df['gender'] = le.fit_transform(df['gender'])  # misalnya: Female=0, Male=1\n",
    "\n",
    "# 3. Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 4. Pisahkan fitur dan target\n",
    "X = df.drop(columns=['dropout', 'grade'])  # Drop kolom grade juga karena berpengaruh\n",
    "y = df['dropout']\n",
    "\n",
    "# 5. Train-test split dengan stratifikasi\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 6. Hitung class weights manual (CatBoost tidak support class_weight='balanced')\n",
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "weight_0 = 1\n",
    "weight_1 = counter[0] / counter[1]  # biasanya 3~6\n",
    "\n",
    "# 7. Buat pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        class_weights=[weight_0, weight_1],\n",
    "        eval_metric='F1',\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 8. Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 9. Predict & Evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n=== ROC AUC Score ===\")\n",
    "print(roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# 10. Cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, cv=5, scoring='f1')\n",
    "print(f\"\\n=== 5-Fold Cross-Validated F1 Score: {scores.mean():.4f} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfbb79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68        79\n",
      "           1       0.14      0.24      0.18        21\n",
      "\n",
      "    accuracy                           0.54       100\n",
      "   macro avg       0.45      0.43      0.43       100\n",
      "weighted avg       0.63      0.54      0.58       100\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[49 30]\n",
      " [16  5]]\n",
      "=== ROC AUC Score ===\n",
      "0.4677516576250753\n",
      "=== 5-Fold Cross-Validated F1 Score: 0.2629 ===\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv('D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/melly_dataset_dropoutcsv.csv')\n",
    "\n",
    "# 2. Encode gender\n",
    "le = LabelEncoder()\n",
    "df['gender'] = le.fit_transform(df['gender'])\n",
    "\n",
    "# 3. Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# 4. Pisahkan fitur dan target\n",
    "X = df.drop(columns=['dropout', 'grade'])  # Dropout sebagai target, grade dibuang agar fair\n",
    "y = df['dropout']\n",
    "\n",
    "# 5. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 6. SMOTE untuk oversampling (opsional, bisa juga tanpa)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 7. Pipeline dengan Logistic Regression (balanced)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# 8. Train model\n",
    "pipeline.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# 9. Evaluasi\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"=== ROC AUC Score ===\")\n",
    "print(roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# 10. Cross-Validation\n",
    "f1_scores = cross_val_score(pipeline, X, y, cv=5, scoring='f1')\n",
    "print(f\"=== 5-Fold Cross-Validated F1 Score: {f1_scores.mean():.4f} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2858a2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87        79\n",
      "           1       0.50      0.29      0.36        21\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.66      0.60      0.62       100\n",
      "weighted avg       0.76      0.79      0.77       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  6]\n",
      " [15  6]]\n",
      "Cross-Validation Accuracy (5-fold): 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Fitur dan target\n",
    "X = df.drop(columns=['dropout', 'grade'])  # Buang target dan grade\n",
    "y = df['dropout']\n",
    "\n",
    "# 2. Kolom kategorik dan numerik\n",
    "categorical_features = ['gender']\n",
    "numerical_features = ['age', 'total_activities_done', 'total_duration_minutes']\n",
    "\n",
    "# 3. Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "    ('num', StandardScaler(), numerical_features)\n",
    "])\n",
    "\n",
    "# 4. Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 5. Split dan training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluasi\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 7. Cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy (5-fold): {scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cfd223",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'activity_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:364\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     col_idx = \u001b[43mall_columns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers.Integral):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'activity_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     34\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m     35\u001b[39m     X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m\n\u001b[32m     36\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 6. Fit model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 7. Predict\u001b[39;00m\n\u001b[32m     42\u001b[39m y_pred = pipeline.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\pipeline.py:654\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    648\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m     )\n\u001b[32m    653\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\pipeline.py:588\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    582\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    583\u001b[39m     step_idx=step_idx,\n\u001b[32m    584\u001b[39m     step_params=routed_params[name],\n\u001b[32m    585\u001b[39m     all_params=raw_params,\n\u001b[32m    586\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\joblib\\memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\pipeline.py:1551\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1553\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1554\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1555\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:993\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    990\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_transformers()\n\u001b[32m    991\u001b[39m n_samples = _num_samples(X)\n\u001b[32m--> \u001b[39m\u001b[32m993\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_remainder(X)\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:552\u001b[39m, in \u001b[36mColumnTransformer._validate_column_callables\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    550\u001b[39m         columns = columns(X)\n\u001b[32m    551\u001b[39m     all_columns.append(columns)\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     transformer_to_input_indices[name] = \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;28mself\u001b[39m._columns = all_columns\n\u001b[32m    555\u001b[39m \u001b[38;5;28mself\u001b[39m._transformer_to_input_indices = transformer_to_input_indices\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:372\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    369\u001b[39m         column_indices.append(col_idx)\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mA given column is not a column of the dataframe\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
      "\u001b[31mValueError\u001b[39m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 1. Dataset\n",
    "# Asumsikan df sudah ada dan bersih\n",
    "X = df.drop(columns=['grade', 'dropout'])  # Buang target dan label lama\n",
    "y = df['grade']  # Target: grade\n",
    "\n",
    "# 2. Fitur numerik & kategorikal\n",
    "categorical_features = ['gender', 'activity_type']\n",
    "numerical_features = ['age', 'total_activities_done', 'total_duration_minutes']\n",
    "\n",
    "# 3. Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "    ('num', StandardScaler(), numerical_features)\n",
    "])\n",
    "\n",
    "# 4. XGBoost Regression pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('regressor', XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 5. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 6. Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 7. Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 8. Evaluation\n",
    "print(\"=== Regression Metrics ===\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# 9. Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "print(f\"5-Fold Cross-Validated RÂ² Score: {cv_scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9831d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76        69\n",
      "           1       0.47      0.48      0.48        31\n",
      "\n",
      "    accuracy                           0.67       100\n",
      "   macro avg       0.62      0.62      0.62       100\n",
      "weighted avg       0.67      0.67      0.67       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[52 17]\n",
      " [16 15]]\n",
      "Cross-Validation Accuracy (5-fold): 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/DROPOUT FINAL.csv')\n",
    "\n",
    "# 1. Fitur dan target\n",
    "X = df.drop(columns=['dropout', 'grade'])  # Buang target dan grade\n",
    "y = df['dropout']\n",
    "\n",
    "# 2. Kolom kategorik dan numerik\n",
    "categorical_features = ['gender']\n",
    "numerical_features = ['age', 'total_activities_done', 'total_duration_minutes']\n",
    "\n",
    "# 3. Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "    ('num', StandardScaler(), numerical_features)\n",
    "])\n",
    "\n",
    "# 4. Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 5. Split dan training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluasi\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 7. Cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy (5-fold): {scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636900e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79        59\n",
      "           1       0.73      0.54      0.62        41\n",
      "\n",
      "    accuracy                           0.73       100\n",
      "   macro avg       0.73      0.70      0.71       100\n",
      "weighted avg       0.73      0.73      0.72       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[51  8]\n",
      " [19 22]]\n",
      "Cross-Validation Accuracy (5-fold): 0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/DATASET DROPOUT 4.csv')\n",
    "\n",
    "# 1. Fitur dan target\n",
    "X = df.drop(columns=['dropout', 'grade'])  # Buang target dan grade\n",
    "y = df['dropout']\n",
    "\n",
    "# 2. Kolom kategorik dan numerik\n",
    "categorical_features = ['gender']\n",
    "numerical_features = ['age', 'total_activities_done', 'total_duration_minutes']\n",
    "\n",
    "# 3. Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "    ('num', StandardScaler(), numerical_features)\n",
    "])\n",
    "\n",
    "# 4. Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 5. Split dan training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluasi\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 7. Cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy (5-fold): {scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d432e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:37:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:37:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79        59\n",
      "           1       0.73      0.54      0.62        41\n",
      "\n",
      "    accuracy                           0.73       100\n",
      "   macro avg       0.73      0.70      0.71       100\n",
      "weighted avg       0.73      0.73      0.72       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[51  8]\n",
      " [19 22]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:37:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:37:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:37:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:37:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy (5-fold): 0.5540\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv('D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/DATASET DROPOUT 4.csv')\n",
    "\n",
    "# 2. Fitur dan target\n",
    "X = df.drop(columns=['dropout','grade'])\n",
    "y = df['dropout']\n",
    "\n",
    "# 3. Kolom kategorikal dan numerikal\n",
    "categorical_features = ['gender']\n",
    "numerical_features = ['age', 'total_activities_done', 'total_duration_minutes']\n",
    "\n",
    "# 4. Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "    ('num', StandardScaler(), numerical_features)\n",
    "])\n",
    "\n",
    "# 5. Pipeline model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# 6. Split train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 7. Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 8. Predict dan evaluasi\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 9. Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy (5-fold): {cv_scores.mean():.4f}\")\n",
    "\n",
    "# # 10. Simpan model\n",
    "# joblib.dump(pipeline, 'xgboost_dropout_model.pkl')\n",
    "# print(\"Model berhasil disimpan sebagai 'xgboost_dropout_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d29df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77        59\n",
      "           1       0.66      0.80      0.73        41\n",
      "\n",
      "    accuracy                           0.75       100\n",
      "   macro avg       0.75      0.76      0.75       100\n",
      "weighted avg       0.77      0.75      0.75       100\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42 17]\n",
      " [ 8 33]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\1.UNI 5th Semester\\6. Advance DataBase\\ADVANCE_DB PROJECT\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:39:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy (5-fold): 0.5380\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv('D:/1.UNI 5th Semester/6. Advance DataBase/ADVANCE_DB PROJECT/ds_project/mellyapp/ml/DATASET DROPOUT 4.csv')\n",
    "\n",
    "# 2. Fitur dan target\n",
    "X = df.drop(columns=['dropout', 'grade'])\n",
    "y = df['dropout']\n",
    "\n",
    "# 3. Kolom kategorikal dan numerikal\n",
    "categorical_features = ['gender']\n",
    "numerical_features = ['age', 'total_activities_done', 'total_duration_minutes']\n",
    "\n",
    "# 4. Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "    ('num', StandardScaler(), numerical_features)\n",
    "])\n",
    "\n",
    "# 5. Hitung scale_pos_weight untuk kelas imbalanced\n",
    "jumlah_kelas_0 = (y == 0).sum()\n",
    "jumlah_kelas_1 = (y == 1).sum()\n",
    "scale = jumlah_kelas_0 / jumlah_kelas_1\n",
    "\n",
    "# 6. Pipeline model dengan XGBClassifier dan scale_pos_weight\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', XGBClassifier(\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 7. Split train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 8. Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 9. Predict dan evaluasi\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 10. Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy (5-fold): {cv_scores.mean():.4f}\")\n",
    "\n",
    "# 11. Simpan model\n",
    "# joblib.dump(pipeline, 'xgboost_dropout_model.pkl')\n",
    "# print(\"Model berhasil disimpan sebagai 'xgboost_dropout_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2176a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
